{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import demultiplexed filtered reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘Data/Demux/SeqRun_2’: File exists\n",
      "mkdir: cannot create directory ‘Data/Demux/SeqRun_2’: File exists\n",
      "mkdir: cannot create directory ‘Data/Demux/SeqRun_2’: File exists\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "met = pd.read_csv('metadata.tsv', sep='\\t', index_col='#SampleID')\n",
    "\n",
    "# sort reads by sequencing run\n",
    "for ri in set(met.Run_index):\n",
    "  tmp = met.loc[met.Run_index == ri]['SeqRun'].tolist()[0]\n",
    "  !mkdir Data/Demux/$tmp\n",
    "  !mv Data/Demux/$ri/* Data/Demux/$tmp\n",
    "  !rm -r Data/Demux/$ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mImported Data/Demux/SeqRun_1 as CasavaOneEightSingleLanePerSampleDirFmt to Data/Demux/SeqRun_1_demux.qza\u001b[0m\n",
      "\u001b[32mImported Data/Demux/SeqRun_2 as CasavaOneEightSingleLanePerSampleDirFmt to Data/Demux/SeqRun_2_demux.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "met = pd.read_csv('metadata.tsv', sep='\\t', index_col='#SampleID')\n",
    "\n",
    "# import reads\n",
    "for sr in set(met.SeqRun):\n",
    "  demux = 'Data/Demux/%s_demux.qza'%sr\n",
    "  \n",
    "  !qiime tools import \\\n",
    "    --type 'SampleData[PairedEndSequencesWithQuality]' \\\n",
    "    --input-path Data/Demux/$sr \\\n",
    "    --input-format CasavaOneEightSingleLanePerSampleDirFmt \\\n",
    "    --output-path $demux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved Visualization to: Data/Demux/SeqRun_1_demux.qzv\u001b[0m\n",
      "\u001b[32mSaved Visualization to: Data/Demux/SeqRun_2_demux.qzv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for sr in set(met.SeqRun):\n",
    "  demux = 'Data/Demux/%s_demux.qza'%sr\n",
    "  deqzv = 'Data/Demux/%s_demux.qzv'%sr\n",
    "  \n",
    "  !qiime demux summarize \\\n",
    "    --i-data $demux \\\n",
    "    --o-visualization $deqzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dada2 denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureTable[Frequency] to: Data/Denoised/SeqRun_1_bac_table.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: Data/Denoised/SeqRun_1_bac_rep-seqs.qza\u001b[0m\n",
      "\u001b[32mSaved SampleData[DADA2Stats] to: Data/Denoised/SeqRun_1_bac_denoising-stats.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: Data/Denoised/SeqRun_1_bac_rep-seqs.qzv\u001b[0m\n",
      "\u001b[32mSaved Visualization to: Data/Denoised/SeqRun_1_bac_denoising-stats.qzv\u001b[0m\n",
      "\u001b[32mSaved Visualization to: Data/Denoised/SeqRun_1_bac_table.qzv\u001b[0m\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: Data/Denoised/SeqRun_2_bac_table.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: Data/Denoised/SeqRun_2_bac_rep-seqs.qza\u001b[0m\n",
      "\u001b[32mSaved SampleData[DADA2Stats] to: Data/Denoised/SeqRun_2_bac_denoising-stats.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: Data/Denoised/SeqRun_2_bac_rep-seqs.qzv\u001b[0m\n",
      "\u001b[32mSaved Visualization to: Data/Denoised/SeqRun_2_bac_denoising-stats.qzv\u001b[0m\n",
      "\u001b[32mSaved Visualization to: Data/Denoised/SeqRun_2_bac_table.qzv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "met = pd.read_csv('metadata.tsv', sep='\\t', index_col='#SampleID')\n",
    "\n",
    "adapter = len(met.LinkerPrimerSequence.tolist()[0])\n",
    "!mkdir Data/Denoised\n",
    "for sr in set(met.SeqRun):\n",
    "  demux = 'Data/Demux/%s_demux.qza'%sr\n",
    "  table = 'Data/Denoised/%s_bac_table.qza'%sr\n",
    "  taqzv = 'Data/Denoised/%s_bac_table.qzv'%sr\n",
    "  repsq = 'Data/Denoised/%s_bac_rep-seqs.qza'%sr\n",
    "  reqzv = 'Data/Denoised/%s_bac_rep-seqs.qzv'%sr\n",
    "  stats = 'Data/Denoised/%s_bac_denoising-stats.qza'%sr\n",
    "  stqzv = 'Data/Denoised/%s_bac_denoising-stats.qzv'%sr\n",
    "  \n",
    "  !qiime dada2 denoise-paired \\\n",
    "    --i-demultiplexed-seqs $demux \\\n",
    "    --p-trim-left-f $adapter \\\n",
    "    --p-trunc-len-f 225 \\\n",
    "    --p-trunc-len-r 185 \\\n",
    "    --p-n-threads 10 \\\n",
    "    --o-table $table \\\n",
    "    --o-representative-sequences $repsq \\\n",
    "    --o-denoising-stats $stats\n",
    "\n",
    "  !qiime feature-table tabulate-seqs \\\n",
    "    --i-data $repsq \\\n",
    "    --o-visualization $reqzv\n",
    "\n",
    "  !qiime metadata tabulate \\\n",
    "    --m-input-file $stats \\\n",
    "    --o-visualization $stqzv\n",
    "\n",
    "  !qiime feature-table summarize \\\n",
    "    --i-table $table \\\n",
    "    --o-visualization $taqzv \\\n",
    "    --m-sample-metadata-file metadata.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge different runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureTable[Frequency] to: Data/merged_table.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!qiime feature-table merge \\\n",
    "  --i-tables Data/Denoised/SeqRun_1_bac_table.qza Data/Denoised/SeqRun_2_bac_table.qza \\\n",
    "  --o-merged-table Data/merged_table.qza\n",
    "\n",
    "!qiime feature-table merge-seqs \\\n",
    "  --i-data Data/Denoised/SeqRun_1_bac_rep-seqs.qza Data/Denoised/SeqRun_2_bac_rep-seqs.qza \\\n",
    "  --o-merged-data Data/merged_rep-seqs.qza\n",
    "\n",
    "!qiime feature-table summarize \\\n",
    "  --i-table Data/merged_table.qza \\\n",
    "  --o-visualization Data/merged_table.qzv \\\n",
    "  --m-sample-metadata-file metadata.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training feature classifier \n",
    "### 138 Silva db ref-seqs and taxonomy were obtained from Qiime2 website and prodused by rescript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureData[Sequence] to: Classifier/ref-seqs.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Extract reference reads\n",
    "!qiime feature-classifier extract-reads \\\n",
    "  --i-sequences Classifier/silva-138-99-seqs.qza \\\n",
    "  --p-f-primer AGAGTTTGATCCTGGCTCAG \\\n",
    "  --p-r-primer TGCTGCCTCCCGTAGGAGT \\\n",
    "  --p-min-length 280 \\\n",
    "  --p-max-length 500 \\\n",
    "  --o-reads Classifier/ref-seqs.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved TaxonomicClassifier to: Classifier/V1-V2_silva_138_classifier.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train classifier\n",
    "!qiime feature-classifier fit-classifier-naive-bayes \\\n",
    "  --i-reference-reads Classifier/ref-seqs.qza \\\n",
    "  --i-reference-taxonomy Classifier/silva-138-99-tax.qza \\\n",
    "  --o-classifier Classifier/V1-V2_silva_138_classifier.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxonomy assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureData[Taxonomy] to: Data/taxonomy_vsearch-sklearn.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: Data/taxonomy_vsearch-sklearn.qzv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!qiime feature-classifier classify-hybrid-vsearch-sklearn \\\n",
    "  --i-query Data/merged_rep-seqs.qza \\\n",
    "  --i-reference-reads Classifier/ref-seqs.qza \\\n",
    "  --i-reference-taxonomy Classifier/silva-138-99-tax.qza \\\n",
    "  --i-classifier Classifier/V1-V2_silva_138_classifier.qza \\\n",
    "  --p-threads 10 \\\n",
    "  --p-no-prefilter \\\n",
    "  --o-classification Data/taxonomy_vsearch-sklearn.qza\n",
    "\n",
    "!qiime metadata tabulate \\\n",
    "  --m-input-file Data/taxonomy_vsearch-sklearn.qza \\\n",
    "  --o-visualization Data/taxonomy_vsearch-sklearn.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureData[Taxonomy] to: Data/taxonomy_blast.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!qiime feature-classifier classify-consensus-blast \\\n",
    "  --i-query Data/merged_rep-seqs.qza \\\n",
    "  --i-reference-reads Classifier/ref-seqs.qza \\\n",
    "  --i-reference-taxonomy Classifier/silva-138-99-tax.qza \\\n",
    "  --o-classification Data/taxonomy_blast.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combo: Combining ASV hashes with last available taxa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install biopython\n",
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mExported Data/merged_table.qza as BIOMV210DirFmt to directory Biom/\u001b[0m\n",
      "\u001b[32mExported Data/taxonomy_vsearch-sklearn.qza as TSVTaxonomyDirectoryFormat to directory Taxa\u001b[0m\n",
      "\u001b[32mExported Data/merged_rep-seqs.qza as DNASequencesDirectoryFormat to directory Rep-seqs/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "# declare Qiime2 generated artifacts here\n",
    "table    = 'Data/merged_table.qza' \n",
    "taxo     = 'Data/taxonomy_vsearch-sklearn.qza'\n",
    "rep_seq  = 'Data/merged_rep-seqs.qza'\n",
    "\n",
    "# export rep-seqs.qza, table.qza and taxonomy.qza\n",
    "!mkdir Biom Taxa Rep-seqs #temp directories\n",
    "\n",
    "!qiime tools export \\\n",
    "  --input-path $table \\\n",
    "  --output-path Biom/\n",
    "\n",
    "!qiime tools export \\\n",
    "  --input-path $taxo \\\n",
    "  --output-path Taxa\n",
    "\n",
    "!qiime tools export \\\n",
    "  --input-path $rep_seq \\\n",
    "  --output-path Rep-seqs/\n",
    "\n",
    "# convert .biom to .tsv\n",
    "!biom convert -i Biom/feature-table.biom -o Biom/feature-table.tsv --to-tsv \n",
    "\n",
    "# *****replacing hashes with combination of taxonomy and beginings of the hashes*****\n",
    "# reading tables\n",
    "taxa = pd.read_csv('Taxa/taxonomy.tsv', sep='\\t')\n",
    "biom = pd.read_csv('Biom/feature-table.tsv', sep='\\t', skiprows=1)\n",
    "\n",
    "#creating a new column with modified taxonomy\n",
    "#I also shortened some annotations and deleted some symbols \n",
    "#that were crashing tree construction with modified files\n",
    "taxa['Taxon'] = taxa.Taxon.replace(';__','').str.replace('[','').str.replace(']','').str.replace('.','')\\\n",
    ".str.replace('/','_').str.replace(\"'\",'').str.replace(' ','_').str.replace('uncultured_bacterium','unc_bac')\\\n",
    ".str.replace('uncultured_rumen','unc_rum').str.replace('unidentified_rumen','unid_rum')\\\n",
    ".str.replace('rumen_bacterium','rum_bac').str.replace('uncultured','unc')\n",
    "\n",
    "taxa['Combo'] =  taxa['Taxon'].str.split(\"__\").str[-1].str.split(\";\").str[-1]\n",
    "taxa.loc[taxa['Combo'].str[:]=='unc_bac','Combo']=taxa['Taxon'].str.split(\"__\").str[-2].str.split(';').str[0]+'_unc_bac'\n",
    "taxa.loc[taxa['Combo'].str[:]=='unc_rum','Combo']=taxa['Taxon'].str.split(\"__\").str[-2].str.split(';').str[0]+'_unc_rum'\n",
    "taxa.loc[taxa['Combo'].str[:]=='unid_rum','Combo']=taxa['Taxon'].str.split(\"__\").str[-2].str.split(';').str[0]+'_unid_rum'\n",
    "taxa.loc[taxa['Combo'].str[:]=='rum_bac','Combo']=taxa['Taxon'].str.split(\"__\").str[-2].str.split(';').str[0]+'_rum_bac'\n",
    "taxa.loc[taxa['Combo'].str[:]=='unc','Combo'] = taxa['Taxon'].str.split(\"__\").str[-2].str.split(';').str[0]+'_unc'\n",
    "\n",
    "#dealing with uncultured taxa to provide additional information\n",
    "for n in range(3,6):\n",
    "  taxa.loc[taxa.Combo.str[:]=='unc_unc_bac','Combo']=taxa.Taxon.str.split(\"__\").str[-n].str.split(';').str[0]+'_unc_bac'\n",
    "  taxa.loc[taxa.Combo.str[:]=='unc_unc_rum','Combo']=taxa.Taxon.str.split(\"__\").str[-n].str.split(';').str[0]+'_unc_rum'\n",
    "  taxa.loc[taxa.Combo.str[:]=='unc_unc','Combo']=taxa.Taxon.str.split(\"__\").str[-n].str.split(';').str[0]+'_unc'\n",
    "\n",
    "#add modified taxonomy information to feature hashes, separating them by '|'\n",
    "biom['#OTU ID'] = taxa['Combo']+'|'+taxa['Feature ID']\n",
    "taxa['Feature ID'] = biom['#OTU ID']\n",
    "taxa = taxa[['Feature ID', 'Taxon', 'Confidence', 'Consensus', 'Method']]\n",
    "\n",
    "### writing modified files\n",
    "biom.to_csv('Biom/feature-table.tsv', sep='\\t', index=False)\n",
    "taxa.to_csv('Taxa/taxonomy.tsv', sep='\\t', index=False)\n",
    "fasta_hash  = r\"Rep-seqs/dna-sequences.fasta\"\n",
    "fasta_combo = r\"Rep-seqs/dna-sequences.fa\"\n",
    "hlist = biom['#OTU ID'].tolist()\n",
    "with open(fasta_hash) as hashes, open(fasta_combo, 'w') as combo:\n",
    "  for record in SeqIO.parse(fasta_hash, 'fasta'):\n",
    "    for h in hlist:\n",
    "      if str(record.id) in h:\n",
    "        combo.write('>'+h+'\\n'+str(record.seq)+'\\n')\n",
    "\n",
    "#some cleaning and renaming\n",
    "!rm $fasta_hash\n",
    "!mv $fasta_combo $fasta_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mImported Biom/feature-table.biom as BIOMV210Format to Data/combo_table.qza\u001b[0m\n",
      "\u001b[32mImported Taxa/taxonomy.tsv as TSVTaxonomyDirectoryFormat to Data/combo_taxonomy.qza\u001b[0m\n",
      "\u001b[32mImported Rep-seqs/dna-sequences.fasta as DNASequencesDirectoryFormat to Data/combo_rep-seqs.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: Data/combo_table.qzv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#creating new rep-seqs.qza, table.qza and taxonomy.qza with modified hashes (added 'combo_' in the name)\n",
    "!biom convert -i Biom/feature-table.tsv -o Biom/feature-table.biom --table-type=\"OTU table\" --to-hdf5\n",
    "\n",
    "!qiime tools import \\\n",
    "  --input-path Biom/feature-table.biom \\\n",
    "  --type 'FeatureTable[Frequency]' \\\n",
    "  --input-format BIOMV210Format \\\n",
    "  --output-path Data/combo_table.qza\n",
    "\n",
    "!qiime tools import \\\n",
    "  --type 'FeatureData[Taxonomy]' \\\n",
    "  --input-path Taxa/taxonomy.tsv \\\n",
    "  --output-path Data/combo_taxonomy.qza\n",
    "\n",
    "!qiime tools import \\\n",
    "  --input-path $fasta_hash \\\n",
    "  --type 'FeatureData[Sequence]' \\\n",
    "  --output-path Data/combo_rep-seqs.qza\n",
    "\n",
    "!rm -r Biom Taxa Rep-seqs #clean temp directories\n",
    "\n",
    "!qiime feature-table summarize \\\n",
    "  --i-table Data/combo_table.qza \\\n",
    "  --m-sample-metadata-file metadata.tsv \\\n",
    "  --o-visualization Data/combo_table.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a tree for phylogenetic diversity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureData[AlignedSequence] to: Data/aligned-rep-seqs.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[AlignedSequence] to: Data/masked-aligned-rep-seqs.qza\u001b[0m\n",
      "\u001b[32mSaved Phylogeny[Unrooted] to: Data/unrooted-tree.qza\u001b[0m\n",
      "\u001b[32mSaved Phylogeny[Rooted] to: Data/rooted-tree.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!qiime phylogeny align-to-tree-mafft-fasttree \\\n",
    "  --i-sequences Data/combo_rep-seqs.qza \\\n",
    "  --p-n-threads 10 \\\n",
    "  --o-alignment Data/aligned-rep-seqs.qza \\\n",
    "  --o-masked-alignment Data/masked-aligned-rep-seqs.qza \\\n",
    "  --o-tree Data/unrooted-tree.qza \\\n",
    "  --o-rooted-tree Data/rooted-tree.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtration to remove low abundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureTable[Frequency] to: Data/filtered-table.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: Data/filtered-table.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: Data/filtered-table.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: Data/filtered-table.qza\u001b[0m\n",
      "\u001b[32mSaved Visualization to: Data/filtered-table.qzv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!qiime feature-table filter-features \\\n",
    "    --i-table Data/combo_table.qza \\\n",
    "    --p-min-frequency 10 \\\n",
    "    --o-filtered-table Data/filtered-table.qza\n",
    "\n",
    "!qiime taxa filter-table \\\n",
    "    --i-table Data/filtered-table.qza \\\n",
    "    --i-taxonomy Data/combo_taxonomy.qza \\\n",
    "    --p-include p__ \\\n",
    "    --o-filtered-table Data/filtered-table.qza\n",
    "\n",
    "!qiime taxa filter-table \\\n",
    "    --i-table Data/filtered-table.qza \\\n",
    "    --i-taxonomy Data/combo_taxonomy.qza \\\n",
    "    --p-exclude mitochondria,chloroplast \\\n",
    "    --o-filtered-table Data/filtered-table.qza\n",
    "\n",
    "!qiime feature-table filter-samples \\\n",
    "    --i-table Data/filtered-table.qza \\\n",
    "    --p-min-features 25 \\\n",
    "    --p-min-frequency 3000 \\\n",
    "    --o-filtered-table Data/filtered-table.qza\n",
    "\n",
    "!qiime feature-table summarize \\\n",
    "    --i-table Data/filtered-table.qza \\\n",
    "    --o-visualization Data/filtered-table.qzv \\\n",
    "    --m-sample-metadata-file metadata.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
